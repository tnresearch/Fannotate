{
  "models": { 
    "openai-community/gpt2-large": {
      "model_dest": "openai-community/gpt2-large",
      "server":"transformers",
      "model_type": "base",
      "chat_format": "unknown",
      "instruction_role": "NA",
      "quantized":false,
      "gated":false
    },  
    "models/Meta-Llama-3-8B-Instruct.Q2_K.gguf": {
      "model_dest": "models/Meta-Llama-3-8B-Instruct.Q2_K.gguf",
      "server":"llama.cpp",
      "model_type": "instruct",
      "chat_format": "chatml",
      "instruction_role": "system",
      "quantized":true,
      "gated":false,
      "notes":":::::::::::: GGUF ::::::::::::"
    },
    "models/Meta-Llama-3.1-70B-Instruct-Q4_K_M.gguf": {
      "model_dest": "models/Meta-Llama-3.1-70B-Instruct-Q4_K_M.gguf",
      "server":"llama.cpp",
      "model_type": "instruct",
      "chat_format": "chatml",
      "instruction_role": "system",
      "quantized":true,
      "gated":false,
      "notes":":::::::::::: GGUF ::::::::::::"
    },  
    "models/Meta-Llama-3-70B-Instruct-IQ1_M.gguf": {
      "model_dest": "models/Meta-Llama-3-70B-Instruct-IQ1_M.gguf",
      "server":"llama.cpp",
      "model_type": "instruct",
      "chat_format": "chatml",
      "instruction_role": "system",
      "quantized":true,
      "gated":false,
      "notes":":::::::::::: GGUF ::::::::::::"
    },  
    "models/Meta-Llama-3.1-70B-Instruct-Q5_K_S.gguf": {
      "model_dest": "models/Meta-Llama-3.1-70B-Instruct-Q5_K_S.gguf",
      "server":"llama.cpp",
      "model_type": "instruct",
      "chat_format": "chatml",
      "instruction_role": "system",
      "quantized":true,
      "gated":false,
      "notes":":::::::::::: GGUF ::::::::::::"
    },  
    "meta-llama/Meta-Llama-3-8B-Instruct": {
      "model_dest": "meta-llama/Meta-Llama-3-8B-Instruct",
      "server":"transformers",
      "model_type": "instruct",
      "chat_format": "chatml",
      "instruction_role": "system",
      "quantized":false,
      "gated":true
    },
    "meta-llama/Meta-Llama-3-8B": {
      "model_dest": "meta-llama/Meta-Llama-3-8B",
      "server":"transformers",
      "model_type": "base",
      "chat_format": "chatml",
      "instruction_role": "system",
      "quantized":false,
      "gated":true
    },
    "meta-llama/Meta-Llama-3.1-8B-Instruct": {
      "model_dest": "meta-llama/Meta-Llama-3.1-8B-Instruct",
      "server":"transformers",
      "model_type": "base",
      "chat_format": "chatml",
      "instruction_role": "system",
      "quantized":false,
      "gated":true
    },
    "meta-llama/Meta-Llama-3.1-8B": {
      "model_dest": "meta-llama/Meta-Llama-3.1-8B",
      "server":"transformers",
      "model_type": "base",
      "chat_format": "chatml",
      "instruction_role": "system",
      "quantized":false,
      "gated":true
    },
    "google/gemma-2-2b-it": {
      "model_dest": "google/gemma-2-2b-it",
      "server":"transformers",
      "model_type": "instruction",
      "chat_format": "chatml",
      "instruction_role": "user",
      "quantized":false,
      "gated":false
    },
    "google/gemma-2-9b-it": {
      "model_dest": "google/gemma-2-9b-it",
      "server":"transformers",
      "model_type": "instruction",
      "chat_format": "chatml",
      "instruction_role": "user",
      "quantized":false,
      "gated":false
    },
    "google/gemma-2-27b-it": {
      "model_dest": "google/gemma-2-27b-it",
      "server":"transformers",
      "model_type": "instruction",
      "chat_format": "chatml",
      "instruction_role": "user",
      "quantized":false,
      "gated":false
    },
    "bineric/NorskGPT-Mistral-7b": {
      "model_dest": "bineric/NorskGPT-Mistral-7b",
      "server":"transformers",
      "model_type": "instruct",
      "chat_format": "alpaca",
      "quantized":false,
      "gated":false,
      "notes":"--------- Bineric ----------"
    },
    "bineric/NorskGPT-Llama3-8b": {
      "model_dest": "bineric/NorskGPT-Llama3-8b",
      "server":"transformers",
      "model_type": "instruct",
      "chat_format": "chatml",
      "instruction_role": "system",
      "quantized":false,
      "gated":false,
      "notes":"--------- Bineric ----------"
    },
    "norallm/normistral-7b-warm-instruct": {
      "model_dest": "norallm/normistral-7b-warm-instruct",
      "server":"transformers",
      "model_type": "instruct",
      "chat_format": "chatml",
      "instruction_role": "system",
      "quantized":false,
      "gated":true,
      "notes":"########## NORALLM ##########"
    },
    "norallm/normistral-7b-warm": {
      "model_dest": "norallm/normistral-7b-warm",
      "server":"transformers",
      "model_type": "base",
      "chat_format": "unknown",
      "instruction_role": "NA",
      "quantized":false,
      "gated":true,
      "notes":"########## NORALLM ##########"
    },
    "NorwAI/NorwAI-Mistral-7B": {
      "model_dest": "NorwAI/NorwAI-Mistral-7B",
      "server":"transformers",
      "model_type": "base",
      "chat_format": "unknown",
      "instruction_role": "NA",
      "quantized":false,
      "gated":true,
      "notes":"=========== NORWAI ============"
    },
    "NorwAI/NorwAI-Llama2-7B": {
      "model_dest": "NorwAI/NorwAI-Llama2-7B",
      "server":"transformers",
      "model_type": "base",
      "chat_format": "unknown",
      "instruction_role": "NA",
      "quantized":false,
      "gated":true,
      "notes":"=========== NORWAI ============"
    },
    "NorwAI/NorwAI-Mistral-7B-instruct": {
      "model_dest": "NorwAI/NorwAI-Mistral-7B-instruct",
      "server":"transformers",
      "model_type": "instruct",
      "chat_format": "chatml",
      "instruction_role": "system",
      "quantized":false,
      "gated":true,
      "notes":"=========== NORWAI ============"
    },
    "NorwAI/NorwAI-Mixtral-8x7B-instruct": {
      "model_dest": "NorwAI/NorwAI-Mixtral-8x7B-instruct",
      "server":"transformers",
      "model_type": "instruct",
      "chat_format": "chatml",
      "instruction_role": "system",
      "quantized":false,
      "gated":true,
      "notes":"=========== NORWAI ============"
    },
    "NorwAI/NorwAI-Mistral-7B-instruct-overfitting": {
      "model_dest": "NorwAI/NorwAI-Mistral-7B-instruct-overfitting",
      "server":"transformers",
      "model_type": "instruct",
      "chat_format": "chatml",
      "instruction_role": "system",
      "quantized":false,
      "gated":true,
      "notes":"=========== NORWAI ============"
    },
    "NorwAI/NorwAI-Mixtral-8x7B": {
      "model_dest": "NorwAI/NorwAI-Mixtral-8x7B",
      "server":"transformers",
      "model_type": "base",
      "chat_format": "unknown",
      "instruction_role": "NA",
      "quantized":false,
      "gated":true,
      "notes":"=========== NORWAI ============"
    }
  }
} 